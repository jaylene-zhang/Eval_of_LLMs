\section{Related work}

Large Language Models (LLMs) have emerged as powerful tools in the field of software engineering, particularly in the domains of code generation and repair. These models, trained on vast corpora of code and natural language, have demonstrated remarkable capabilities in understanding and producing programming language syntax and semantics.

Large language models (LLMs) for code generation refer to the use of LLM to generate source code from natural language descriptions, a process also known as a natural-language-to-code task. Typically, these natural language descriptions encompass programming problem statements (or docstrings) and may optionally include some programming context. Code generation has been a long-standing challenge in software engineering. LLMs have shown significant promise in this area, offering the potential to increase developer productivity and assist in rapid prototyping \cite{10.5555/3618408.3618894,wu2024repoformerselectiveretrievalrepositorylevel,DBLP:conf/acl/LuDHGHS22}. For example, LLMs can offer immediate feedback on students' programming assignments and produce varied code samples to illustrate programming principles \cite{kumar2024impactguidanceinteractionstrategies}. An experiment by \cite{10.1145/3545945.3569830} reveals that learners with access to Codex during the training phase performed slightly better on the evaluation. The work by \cite{yetiştiren2023evaluatingcodequalityaiassisted} used the latest versions of ChatGPT, GitHub Copilot, and Amazon CodeWhisperer to generate Python code using the benchmark HumanEval Dataset, and they achieved 65.2\%, 46.3\%, and 31.1\% of the time, respectively. A study by \cite{10.1145/3544548.3580919} investigates how a pedagogically-designed LLM-based chatbot supports students’ debugging efforts in an introductory programming course. Their data revealed that students appreciated the content and experiential knowledge provided by the chatbot, but did not view it as a primary source for learning debugging strategies. 



Similarly, code repair, which involves identifying and correcting errors in existing code, has seen advancements through the application of LLMs. These models can potentially detect both syntactic and semantic errors, suggesting corrections that adhere to best practices and maintain code consistency \cite{DBLP:conf/icse/JiangL021, parasaram2024factselectionproblemllmbased, olausson2024selfrepairsilverbulletcode}. Prenner et al. \cite{10.1145/3524459.3527351} conducted a small-scale evaluation for the Codex model on a simple dataset containing both Java and Python versions of buggy algorithm implementations. Codex is given the buggy function and by using prompt engineering, are then asked to generate a complete fixed function. The results show that Codex is competitive with state-of-the-art learning-based APR tools in Python but worse in Java. In contrast, we show that by using our repair settings, LLMs are able to outperform state-of-the-art APR tools on both Java and Python. Kolak et al. \cite{osti_10340618} also used Codex along with 2 smaller LLMs and evaluated their ability to generate the correct patch line when given the code prefix on the same dataset as the previous work [32]. The evaluation demonstrated the scaling effect of LLMs where the repair results can be improved by using larger models.

The importance of these capabilities extends beyond professional software development into the realm of programming education. LLMs capable of generating and repairing code could serve as powerful educational tools, providing instant feedback to students, assisting in debugging, and offering explanations for complex programming concepts \cite{10.1145/3597503.3639219, 10.1145/3544548.3580919, 10.1145/3631802.3631806, 10.1145/3613904.3642706, jury2024evaluating}. In addition, Kiesler and Schiffner \cite{kiesler2023largelanguagemodelsintroductory} assessed the capabilities of ChatGPT-3.5 and GPT-4 in solving introductory Python programming tasks sourced from CodingBat. Supporting discussions on LLMs’ application in programming education, particularly with development assistants, additional references such as Asare et al. \cite{10.1007/s10664-023-10380-1}, Pearce et al. \cite{DBLP:conf/sp/PearceA0DK22} and Dakhel et al. \cite{DBLP:journals/jss/DakhelMNKDJ23} provide insights into the integration of AI tools within software development environments. These studies collectively underscore the transformative impact of LLMs on programming education, suggesting avenues for future research in optimizing their use for educational enhancement


However, their use also raises important questions about academic integrity and the development of core programming skills.[citations]
