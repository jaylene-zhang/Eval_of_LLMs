
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries

% incol when the chapter is 'text' - due to presence of editor (different to author)



@misc{yetiştiren2023evaluatingcodequalityaiassisted,
      title={Evaluating the Code Quality of AI-Assisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT}, 
      author={Burak Yetiştiren and Işık Özsoy and Miray Ayerdem and Eray Tüzün},
      year={2023},
      eprint={2304.10778},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2304.10778}, 
}



@inproceedings{NEURIPS2023_43e9d647,
 author = {Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and ZHANG, LINGMING},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {21558--21572},
 publisher = {Curran Associates, Inc.},
 title = {Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/43e9d647ccd3e4b7b5baab53f0368686-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}


@INPROCEEDINGS{10403378,
  author={Wang, Jianxun and Chen, Yixiang},
  booktitle={2023 IEEE International Conference on Medical Artificial Intelligence (MedAI)}, 
  title={A Review on Code Generation with LLMs: Application and Evaluation}, 
  year={2023},
  volume={},
  number={},
  pages={284-289},
  keywords={Productivity;Computer science;Codes;Writing;Encoding;Task analysis;Software engineering;large language models (LLMs);code generation;code completion;automatic program repair;code quality evaluation},
  doi={10.1109/MedAI59581.2023.00044}}


@article{zheng2024towards,
  title={Towards more realistic evaluation of LLM-based code generation: an experimental study and beyond},
  author={Zheng, Dewu and Wang, Yanlin and Shi, Ensheng and Zhang, Ruikai and Ma, Yuchi and Zhang, Hongyu and Zheng, Zibin},
  journal={arXiv preprint arXiv:2406.06918},
  year={2024}
}

@article{jiang2024survey,
  title={A Survey on Large Language Models for Code Generation},
  author={Jiang, Juyong and Wang, Fan and Shen, Jiasi and Kim, Sungju and Kim, Sunghun},
  journal={arXiv preprint arXiv:2406.00515},
  year={2024}
}

@inproceedings{10.1145/3661167.3661221,
author = {Coignion, Tristan and Quinton, Cl\'{e}ment and Rouvoy, Romain},
title = {A Performance Study of LLM-Generated Code on Leetcode},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661221},
doi = {10.1145/3661167.3661221},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {79–89},
numpages = {11},
location = {Salerno, Italy},
series = {EASE '24}
}


@inproceedings{10.1109/ICSE48619.2023.00181,
author = {Mastropaolo, Antonio and Pascarella, Luca and Guglielmi, Emanuela and Ciniselli, Matteo and Scalabrino, Simone and Oliveto, Rocco and Bavota, Gabriele},
title = {On the Robustness of Code Generation Techniques: An Empirical Study on GitHub Copilot},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00181},
doi = {10.1109/ICSE48619.2023.00181},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {2149–2160},
numpages = {12},
keywords = {empirical study, recommender systems},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3545945.3569830,
author = {Wermelinger, Michel},
title = {Using GitHub Copilot to Solve Simple Programming Problems},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569830},
doi = {10.1145/3545945.3569830},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {172–178},
numpages = {7},
keywords = {academic integrity, code explanation, code generation, introductory programming, novice programming, openai codex, programming exercises, programming patterns, test generation},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

% alphacode
@INPROCEEDINGS{9978175,
  author={Lertbanjongngam, Sila and Chinthanet, Bodin and Ishio, Takashi and Kula, Raula Gaikovina and Leelaprute, Pattara and Manaskasemsak, Bundit and Rungsawang, Arnon and Matsumoto, Kenichi},
  booktitle={2022 IEEE 16th International Workshop on Software Clones (IWSC)}, 
  title={An Empirical Evaluation of Competitive Programming AI: A Case Study of AlphaCode}, 
  year={2022},
  volume={},
  number={},
  pages={10-15},
  keywords={Codes;Conferences;Natural languages;Cloning;Manuals;Programming;Licenses;code generation;code similarity;code performance},
  doi={10.1109/IWSC55060.2022.00010}}


% codex
@inproceedings{10.1145/3597503.3639219,
author = {Du, Xueying and Liu, Mingwei and Wang, Kaixin and Wang, Hanlin and Liu, Junwei and Chen, Yixuan and Feng, Jiayi and Sha, Chaofeng and Peng, Xin and Lou, Yiling},
title = {Evaluating Large Language Models in Class-Level Code Generation},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639219},
doi = {10.1145/3597503.3639219},
abstract = {Recently, many large language models (LLMs) have been proposed, showing advanced proficiency in code generation. Meanwhile, many efforts have been dedicated to evaluating LLMs on code generation benchmarks such as HumanEval. Although being very helpful for comparing different LLMs, existing evaluation focuses on a simple code generation scenario (i.e., function-level or statement-level code generation), which mainly asks LLMs to generate one single code unit (e.g., a function or a statement) for the given natural language description. Such evaluation focuses on generating independent and often small-scale code units, thus leaving it unclear how LLMs perform in real-world software development scenarios.To fill this knowledge gap, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e., class-level code generation. Compared with existing code generation benchmarks, it better reflects real-world software development scenarios due to it comprising broader contextual dependencies and multiple, interdependent units of code. We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours. Based on the new benchmark ClassEval, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation. Based on our results, we find that all LLMs perform much worse on class-level code generation compared to the method-level. While GPT models still dominate other LLMs on class-level code generation, the performance rankings of other models on method-level code generation no longer holds for class-level code generation. Besides, most models (except GPT models) perform better when generating the class method by method; and they have the limited ability of generating dependent code. Based on our findings, we call for software engineering (SE) researchers' expertise to build more LLM benchmarks based on practical and complicated software development scenarios.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {81},
numpages = {13},
keywords = {class-level code generation, large language model, benchmark},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3558489.3559072,
author = {Yetistiren, Burak and Ozsoy, Isik and Tuzun, Eray},
title = {Assessing the quality of GitHub copilot’s code generation},
year = {2022},
isbn = {9781450398602},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3558489.3559072},
doi = {10.1145/3558489.3559072},
booktitle = {Proceedings of the 18th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {62–71},
numpages = {10},
keywords = {empirical study, code generation, code completion, GitHub Copilot, AI pair programmer},
location = {Singapore, Singapore},
series = {PROMISE 2022}
}

@misc{agarwal2024copilotevaluationharnessevaluating,
      title={Copilot Evaluation Harness: Evaluating LLM-Guided Software Programming}, 
      author={Anisha Agarwal and Aaron Chan and Shubham Chandel and Jinu Jang and Shaun Miller and Roshanak Zilouchian Moghaddam and Yevhen Mohylevskyy and Neel Sundaresan and Michele Tufano},
      year={2024},
      eprint={2402.14261},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2402.14261}, 
}

@inproceedings{10.1145/3544548.3580919,
author = {Kazemitabaar, Majeed and Chow, Justin and Ma, Carl Ka To and Ericson, Barbara J. and Weintrop, David and Grossman, Tovi},
title = {Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580919},
doi = {10.1145/3544548.3580919},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {455},
numpages = {23},
keywords = {AI Coding Assistants, AI-Assisted Pair-Programming, ChatGPT, Copilot, GPT-3, Introductory Programming, K-12 Computer Science Education, Large Language Models, OpenAI Codex},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3491101.3519665,
author = {Vaithilingam, Priyan and Zhang, Tianyi and Glassman, Elena L.},
title = {Expectation vs.&nbsp;Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519665},
doi = {10.1145/3491101.3519665},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {332},
numpages = {7},
keywords = {github copilot, large language model},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@inproceedings{10.1145/3631802.3631806,
author = {Kazemitabaar, Majeed and Hou, Xinying and Henley, Austin and Ericson, Barbara Jane and Weintrop, David and Grossman, Tovi},
title = {How Novices Use LLM-based Code Generators to Solve CS1 Coding Tasks in a Self-Paced Learning Environment},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631806},
doi = {10.1145/3631802.3631806},
articleno = {3},
numpages = {12},
keywords = {ChatGPT, Copilot, Introductory Programming, Large Language Models, OpenAI Codex, Self-paced Learning, Self-regulation},
location = {Koli, Finland},
series = {Koli Calling '23}
}


@misc{wang2024softwaretestinglargelanguage,
      title={Software Testing with Large Language Models: Survey, Landscape, and Vision}, 
      author={Junjie Wang and Yuchao Huang and Chunyang Chen and Zhe Liu and Song Wang and Qing Wang},
      year={2024},
      eprint={2307.07221},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2307.07221}, 
}

@inproceedings{10.1145/3613904.3642706,
author = {Nguyen, Sydney and Babe, Hannah McLean and Zi, Yangtian and Guha, Arjun and Anderson, Carolyn Jane and Feldman, Molly Q},
title = {How Beginning Programmers and Code LLMs (Mis)read Each Other},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642706},
doi = {10.1145/3613904.3642706},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {651},
numpages = {26},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.5555/3618408.3618894,
author = {Guo, Daya and Xu, Canwen and Duan, Nan and Yin, Jian and McAuley, Julian},
title = {LongCoder: a long-range pre-trained language model for code completion},
year = {2023},
publisher = {JMLR.org},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {486},
numpages = {10},
location = {Honolulu, Hawaii, USA},
series = {ICML'23}
}

@inproceedings{DBLP:conf/acl/LuDHGHS22,
  author       = {Shuai Lu and
                  Nan Duan and
                  Hojae Han and
                  Daya Guo and
                  Seung{-}won Hwang and
                  Alexey Svyatkovskiy},
  editor       = {Smaranda Muresan and
                  Preslav Nakov and
                  Aline Villavicencio},
  title        = {ReACC: {A} Retrieval-Augmented Code Completion Framework},
  booktitle    = {Proceedings of the 60th Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
                  May 22-27, 2022},
  pages        = {6227--6240},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.acl-long.431},
  doi          = {10.18653/V1/2022.ACL-LONG.431},
  timestamp    = {Mon, 01 Aug 2022 16:27:39 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/LuDHGHS22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@misc{wu2024repoformerselectiveretrievalrepositorylevel,
      title={Repoformer: Selective Retrieval for Repository-Level Code Completion}, 
      author={Di Wu and Wasi Uddin Ahmad and Dejiao Zhang and Murali Krishna Ramanathan and Xiaofei Ma},
      year={2024},
      eprint={2403.10059},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2403.10059}, 
}

@inproceedings{DBLP:conf/icse/JiangL021,
  author       = {Nan Jiang and
                  Thibaud Lutellier and
                  Lin Tan},
  title        = {{CURE:} Code-Aware Neural Machine Translation for Automatic Program
                  Repair},
  booktitle    = {43rd {IEEE/ACM} International Conference on Software Engineering,
                  {ICSE} 2021, Madrid, Spain, 22-30 May 2021},
  pages        = {1161--1173},
  publisher    = {{IEEE}},
  year         = {2021},
  url          = {https://doi.org/10.1109/ICSE43902.2021.00107},
  doi          = {10.1109/ICSE43902.2021.00107},
  timestamp    = {Fri, 22 Sep 2023 09:30:11 +0200},
  biburl       = {https://dblp.org/rec/conf/icse/JiangL021.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{olausson2024selfrepairsilverbulletcode,
      title={Is Self-Repair a Silver Bullet for Code Generation?}, 
      author={Theo X. Olausson and Jeevana Priya Inala and Chenglong Wang and Jianfeng Gao and Armando Solar-Lezama},
      year={2024},
      eprint={2306.09896},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.09896}, 
}

@misc{parasaram2024factselectionproblemllmbased,
      title={The Fact Selection Problem in LLM-Based Program Repair}, 
      author={Nikhil Parasaram and Huijie Yan and Boyu Yang and Zineb Flahy and Abriele Qudsi and Damian Ziaber and Earl Barr and Sergey Mechtaev},
      year={2024},
      eprint={2404.05520},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2404.05520}, 
}

@inproceedings{10.1145/3524459.3527351,
author = {Prenner, Julian Aron and Babii, Hlib and Robbes, Romain},
title = {Can OpenAI's codex fix bugs? an evaluation on QuixBugs},
year = {2022},
isbn = {9781450392853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524459.3527351},
doi = {10.1145/3524459.3527351},
booktitle = {Proceedings of the Third International Workshop on Automated Program Repair},
pages = {69–75},
numpages = {7},
keywords = {QuixBugs, automatic program repair, codex, deep learning},
location = {Pittsburgh, Pennsylvania},
series = {APR '22}
}

@article{osti_10340618,
place = {Country unknown/Code not available}, title = {Patch Generation with Language Models: Feasibility and Scaling Behavior}, url = {https://par.nsf.gov/biblio/10340618}, abstractNote = {Large language models have shown a propensity for generating correct, multi-line programs from natural language prompts. Given past findings highlighting that bugs and patches can be distinguished by predictability according to simple language models, it is natural to ask if modern, large neural options lend themselves especially well to program repair without any calibration. We study this in the context of one-line bugs, providing a series of models of varying scales (from 160M to 12B parameters) with the context preceding a buggy line in 72 Java and Python programs and analyze the rank at which the correct patch (and original buggy line) is generated, if at all. Our results highlight a noticeable correlation of model size with test-passing accuracy and patch ranking quality, as well as several other findings related to the differences between the two languages and the propensity for especially the largest models to generate candidate patches that closely resemble (if not exactly match), the original developer patch.}, journal = {Deep Learning for Code Workshop}, author = {Kolak, Sophia D. and Martins, Ruben and Le Goues, Claire and Hellendoorn, Vincent Josua}, }


@inproceedings{jury2024evaluating,
  title={Evaluating llm-generated worked examples in an introductory programming course},
  author={Jury, Breanna and Lorusso, Angela and Leinonen, Juho and Denny, Paul and Luxton-Reilly, Andrew},
  booktitle={Proceedings of the 26th Australasian Computing Education Conference},
  pages={77--86},
  year={2024}
}

@misc{kiesler2023largelanguagemodelsintroductory,
      title={Large Language Models in Introductory Programming Education: ChatGPT's Performance and Implications for Assessments}, 
      author={Natalie Kiesler and Daniel Schiffner},
      year={2023},
      eprint={2308.08572},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2308.08572}, 
}


@article{10.1007/s10664-023-10380-1,
author = {Asare, Owura and Nagappan, Meiyappan and Asokan, N.},
title = {Is GitHub’s Copilot as bad as humans at introducing vulnerabilities in code?},
year = {2023},
issue_date = {Nov 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-023-10380-1},
doi = {10.1007/s10664-023-10380-1},
journal = {Empirical Softw. Engg.},
month = {sep},
numpages = {24},
keywords = {language models, software engineering, code security, copilot}
}

@inproceedings{DBLP:conf/sp/PearceA0DK22,
  author       = {Hammond Pearce and
                  Baleegh Ahmad and
                  Benjamin Tan and
                  Brendan Dolan{-}Gavitt and
                  Ramesh Karri},
  title        = {Asleep at the Keyboard? Assessing the Security of GitHub Copilot's
                  Code Contributions},
  booktitle    = {43rd {IEEE} Symposium on Security and Privacy, {SP} 2022, San Francisco,
                  CA, USA, May 22-26, 2022},
  pages        = {754--768},
  publisher    = {{IEEE}},
  year         = {2022},
  url          = {https://doi.org/10.1109/SP46214.2022.9833571},
  doi          = {10.1109/SP46214.2022.9833571},
  timestamp    = {Sun, 12 Nov 2023 02:10:03 +0100},
  biburl       = {https://dblp.org/rec/conf/sp/PearceA0DK22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/jss/DakhelMNKDJ23,
  author       = {Arghavan Moradi Dakhel and
                  Vahid Majdinasab and
                  Amin Nikanjam and
                  Foutse Khomh and
                  Michel C. Desmarais and
                  Zhen Ming (Jack) Jiang},
  title        = {GitHub Copilot {AI} pair programmer: Asset or Liability?},
  journal      = {J. Syst. Softw.},
  volume       = {203},
  pages        = {111734},
  year         = {2023},
  url          = {https://doi.org/10.1016/j.jss.2023.111734},
  doi          = {10.1016/J.JSS.2023.111734},
  timestamp    = {Tue, 07 May 2024 20:24:55 +0200},
  biburl       = {https://dblp.org/rec/journals/jss/DakhelMNKDJ23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@misc{kumar2024impactguidanceinteractionstrategies,
      title={Impact of Guidance and Interaction Strategies for LLM Use on Learner Performance and Perception}, 
      author={Harsh Kumar and Ilya Musabirov and Mohi Reza and Jiakai Shi and Xinyuan Wang and Joseph Jay Williams and Anastasia Kuzminykh and Michael Liut},
      year={2024},
      eprint={2310.13712},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2310.13712}, 
}



@INPROCEEDINGS{10196869,
  author={Feng, Yunhe and Vanam, Sreecharan and Cherukupally, Manasa and Zheng, Weijian and Qiu, Meikang and Chen, Haihua},
  booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Investigating Code Generation Performance of ChatGPT with Crowdsourcing Social Data}, 
  year={2023},
  volume={},
  number={},
  pages={876-885},
  keywords={Codes;Social networking (online);Debugging;Chatbots;Software;Task analysis;Interviews;ChatGPT;Coding Generation;Software Engineering;Large Language Models (LLMs);Generative Models;Social Media},
  doi={10.1109/COMPSAC57700.2023.00117}}



@inproceedings{Chen2023GPTutorAC,
  title={GPTutor: a ChatGPT-powered programming tool for code explanation},
  author={Eason Chen and Ray Huang and Hanze Chen and Yuen-Hsien Tseng and Liang-Yi Li},
  booktitle={International Conference on Artificial Intelligence in Education},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:258461009}
}

@article{article,
author = {Surameery, Nigar and Shakor, Mohammed},
year = {2023},
month = {01},
pages = {17-22},
title = {Use Chat GPT to Solve Programming Bugs},
journal = {International Journal of Information technology and Computer Engineering},
doi = {10.55529/ijitc.31.17.22}
}

@inproceedings{10.1145/3639474.3640076,
author = {Xue, Yuankai and Chen, Hanlin and Bai, Gina R. and Tairas, Robert and Huang, Yu},
title = {Does ChatGPT Help With Introductory Programming?An Experiment of Students Using ChatGPT in CS1},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640076},
doi = {10.1145/3639474.3640076},
pages = {331–341},
numpages = {11},
keywords = {CS education, CS1, generative AI, ChatGPT, OOP},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@misc{hicke2023aitaintelligentquestionanswerteaching,
      title={AI-TA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs}, 
      author={Yann Hicke and Anmol Agarwal and Qianou Ma and Paul Denny},
      year={2023},
      eprint={2311.02775},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2311.02775}, 
}


@misc{anishka2024chatgptplayroleteaching,
      title={Can ChatGPT Play the Role of a Teaching Assistant in an Introductory Programming Course?}, 
      author={Anishka and Atharva Mehta and Nipun Gupta and Aarav Balachandran and Dhruv Kumar and Pankaj Jalote},
      year={2024},
      eprint={2312.07343},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2312.07343}, 
}







% citations for LRL
%
%
@misc{deng2024assessingcodegenerationintermediate,
      title={Assessing Code Generation with Intermediate Languages}, 
      author={Xun Deng and Sicheng Zhong and Honghua Dong and Jingyu Hu and Sidi Mohamed Beillahi and Xujie Si and Fan Long},
      year={2024},
      eprint={2407.05411},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2407.05411}, 
}

@misc{mora2024syntheticprogrammingelicitationtexttocode,
      title={Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages}, 
      author={Federico Mora and Justin Wong and Haley Lepe and Sahil Bhatia and Karim Elmaaroufi and George Varghese and Joseph E. Gonzalez and Elizabeth Polgreen and Sanjit A. Seshia},
      year={2024},
      eprint={2406.03636},
      archivePrefix={arXiv},
      primaryClass={cs.PL},
      url={https://arxiv.org/abs/2406.03636}, 
}

@article{10.1145/3689735,
author = {Cassano, Federico and Gouwar, John and Lucchetti, Francesca and Schlesinger, Claire and Freeman, Anders and Anderson, Carolyn Jane and Feldman, Molly Q and Greenberg, Michael and Jangda, Abhinav and Guha, Arjun},
title = {Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3689735},
doi = {10.1145/3689735},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {295},
numpages = {32},
keywords = {Large Language Models trained on Code}
}